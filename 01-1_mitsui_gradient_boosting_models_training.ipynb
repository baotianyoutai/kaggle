{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":94771,"databundleVersionId":13044405,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!mkdir oof models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T15:55:14.850466Z","iopub.execute_input":"2025-07-27T15:55:14.850812Z","iopub.status.idle":"2025-07-27T15:55:14.975792Z","shell.execute_reply.started":"2025-07-27T15:55:14.850784Z","shell.execute_reply":"2025-07-27T15:55:14.974861Z"}},"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘oof’: File exists\nmkdir: cannot create directory ‘models’: File exists\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import random\nimport numpy as np\nimport os\n\nimport pandas as pd\nimport polars as pl\n\nfrom pathlib import Path\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import Pool, CatBoostRegressor\n\nimport pickle\nimport gc\n\n\n# import scipy as sp\n# from glob import glob\n# import joblib\n# import itertools\n# from tqdm.auto import tqdm\n# import torch\n# from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GroupKFold\n# from sklearn.metrics import log_loss, roc_auc_score, matthews_corrcoef, f1_score\n# from sklearn.metrics import mean_squared_error, r2_score\n# from sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T15:55:14.977579Z","iopub.execute_input":"2025-07-27T15:55:14.978000Z","iopub.status.idle":"2025-07-27T15:55:17.870364Z","shell.execute_reply.started":"2025-07-27T15:55:14.977968Z","shell.execute_reply":"2025-07-27T15:55:17.869473Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class CFG:\n    VER = 1\n    DATA_PATH = Path(\"/kaggle/input/mitsui-commodity-prediction-challenge\")\n    SEED = 42\n    N_SPLIT = 5\n    METHOD_LIST = [\"lightgbm\", \"xgboost\", \"catboost\"]\n    MODEL_DATA_PATH = Path(\"./models\")\n    OOF_DATA_PATH = Path(\"./oof\")\n\n    # USE_GPU = torch.cuda.is_available()\n    # metric = 'rmse'\n    # metric_maximize_flag = False\n\n    \n    num_boost_round = 2500\n    early_stopping_round = 10\n    verbose = 50\n\n    # https://lightgbm.readthedocs.io/en/latest/Parameters.html\n    regression_lgb_params = {\n        \"objective\": \"regression\",\n        \"metric\": \"rmse\",\n        \"learning_rate\": 0.005, # default = 0.1\n        \"num_leaves\": 6, # default = 31\n        \"seed\": SEED      \n    }\n\n    regression_xgb_params = {\n        \"objective\": \"reg:squarederror\",\n        \"eval_metric\": \"rmse\",\n        'learning_rate': 0.005, \n        'max_depth': 4,\n        'random_state': SEED,\n    }\n\n    regression_cat_params = {\n        'loss_function': 'RMSE',\n        'learning_rate': 0.005, \n        'iterations': num_boost_round, \n        'depth': 4, \n        'random_seed': SEED,\n    }\n    \n    \n    PREFIX = f\"seed{SEED}_ver{VER}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T15:55:17.871243Z","iopub.execute_input":"2025-07-27T15:55:17.871811Z","iopub.status.idle":"2025-07-27T15:55:17.878007Z","shell.execute_reply.started":"2025-07-27T15:55:17.871780Z","shell.execute_reply":"2025-07-27T15:55:17.877178Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\nseed(CFG.SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T15:55:17.879651Z","iopub.execute_input":"2025-07-27T15:55:17.879998Z","iopub.status.idle":"2025-07-27T15:55:17.896901Z","shell.execute_reply.started":"2025-07-27T15:55:17.879975Z","shell.execute_reply":"2025-07-27T15:55:17.896036Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### The competition's metric\n- is a variant of the Sharpe ratio, computed by dividing the mean Spearman rank correlation between the predictions and targets by the standard deviation. ","metadata":{}},{"cell_type":"code","source":"\n\nSOLUTION_NULL_FILLER = -999999\n\n\ndef rank_correlation_sharpe_ratio(merged_df: pd.DataFrame) -> float:\n    \"\"\"\n    Calculates the rank correlation between predictions and target values,\n    and returns its Sharpe ratio (mean / standard deviation).\n\n    :param merged_df: DataFrame containing prediction columns (starting with 'prediction_')\n                      and target columns (starting with 'target_')\n    :return: Sharpe ratio of the rank correlation\n    :raises ZeroDivisionError: If the standard deviation is zero\n    \"\"\"\n    prediction_cols = [col for col in merged_df.columns if col.startswith('prediction_')]\n    target_cols = [col for col in merged_df.columns if col.startswith('target_')]\n\n    def _compute_rank_correlation(row):\n        non_null_targets = [col for col in target_cols if not pd.isnull(row[col])]\n        matching_predictions = [col for col in prediction_cols if col.replace('prediction', 'target') in non_null_targets]\n        if not non_null_targets:\n            raise ValueError('No non-null target values found')\n        if row[non_null_targets].std(ddof=0) == 0 or row[matching_predictions].std(ddof=0) == 0:\n            raise ZeroDivisionError('Denominator is zero, unable to compute rank correlation.')\n        return np.corrcoef(row[matching_predictions].rank(method='average'), row[non_null_targets].rank(method='average'))[0, 1]\n\n    daily_rank_corrs = merged_df.apply(_compute_rank_correlation, axis=1)\n    std_dev = daily_rank_corrs.std(ddof=0)\n    if std_dev == 0:\n        raise ZeroDivisionError('Denominator is zero, unable to compute Sharpe ratio.')\n    sharpe_ratio = daily_rank_corrs.mean() / std_dev\n    return float(sharpe_ratio)\n\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n    \"\"\"\n    Calculates the rank correlation between predictions and target values,\n    and returns its Sharpe ratio (mean / standard deviation).\n    \"\"\"\n    del solution[row_id_column_name]\n    del submission[row_id_column_name]\n    assert all(solution.columns == submission.columns)\n\n    submission = submission.rename(columns={col: col.replace('target_', 'prediction_') for col in submission.columns})\n\n    # Not all securities trade on all dates, but solution files cannot contain nulls.\n    # The filler value allows us to handle trading halts, holidays, & delistings.\n    solution = solution.replace(SOLUTION_NULL_FILLER, None)\n    return rank_correlation_sharpe_ratio(pd.concat([solution, submission], axis='columns'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T15:55:17.897740Z","iopub.execute_input":"2025-07-27T15:55:17.898243Z","iopub.status.idle":"2025-07-27T15:55:17.914190Z","shell.execute_reply.started":"2025-07-27T15:55:17.898220Z","shell.execute_reply":"2025-07-27T15:55:17.913142Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### difine model training","metadata":{}},{"cell_type":"code","source":"def lightgbm_training(x_train: pd.DataFrame, y_train: pd.DataFrame, \n                      x_valid: pd.DataFrame, y_valid: pd.DataFrame):\n    \n    lgb_train = lgb.Dataset(x_train, y_train)\n    lgb_valid = lgb.Dataset(x_valid, y_valid)\n\n    # https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.train.html\n    model = lgb.train(\n        params = CFG.regression_lgb_params,\n        train_set = lgb_train,\n        valid_sets = [lgb_train, lgb_valid],\n        num_boost_round = CFG.num_boost_round,\n        callbacks = [\n            lgb.early_stopping(stopping_rounds = CFG.early_stopping_round, verbose = CFG.verbose),\n            lgb.log_evaluation(period = CFG.verbose),\n        ]\n    )\n    \n    # Predict validation\n    valid_pred = model.predict(x_valid)\n    \n    return model, valid_pred\n\n# https://xgboost.readthedocs.io/en/stable/python/python_api.html\ndef xgboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame,\n                    x_valid: pd.DataFrame, y_valid: pd.DataFrame):\n    \n    xgb_train = xgb.DMatrix(data = x_train, label = y_train)\n    xgb_valid = xgb.DMatrix(data = x_valid, label = y_valid)\n    \n    model = xgb.train(\n        params = CFG.regression_xgb_params,\n        dtrain = xgb_train,\n        num_boost_round = CFG.num_boost_round,\n        evals = [(xgb_train, \"train\"), (xgb_valid, \"eval\")],\n        early_stopping_rounds = CFG.early_stopping_round,\n        verbose_eval = CFG.verbose,\n    )\n    \n    # Predict validation\n    valid_pred = model.predict(xgb.DMatrix(x_valid))\n    return model, valid_pred\n\ndef catboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame,\n                      x_valid: pd.DataFrame, y_valid: pd.DataFrame):\n    # initialize Pool\n    cat_train = Pool(data = x_train, label = y_train)\n    cat_valid = Pool(data = x_valid, label = y_valid)\n    # specify the training parameters\n    model = CatBoostRegressor(**CFG.regression_cat_params)\n    # train the model\n    model.fit(\n        cat_train,\n        eval_set = [cat_valid],\n        early_stopping_rounds = CFG.early_stopping_round,\n        verbose = CFG.verbose,\n        use_best_model = True,\n    )\n    valid_pred = model.predict(x_valid)\n    return model, valid_pred\n\ndef gradient_boosting_model_cv_training(method: str, train_df: pd.DataFrame, features: list,\n                                        target_cols: list):\n    # Create a numpy array to store out of folds predictions\n    oof_predictions = np.zeros(len(train_df))\n    oof_fold = np.zeros(len(train_df))\n    for fold in range(CFG.N_SPLIT):\n        print(\"-\" * 50)\n        print(f\"{method} training fold {fold + 1}\")\n        x_train = train_df[train_df[\"cv_flag\"]!=fold + 1][features]\n        y_train = train_df[train_df[\"cv_flag\"]!=fold + 1][\"target\"]\n        \n        \n        valid_df = train_df[train_df[\"cv_flag\"] == fold + 1].copy()\n        x_valid = valid_df[features]\n        y_valid = valid_df['target']\n        \n        if method == \"lightgbm\":\n            model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid)\n            ## 2. feature importance\n            importance_df = pd.DataFrame(model.feature_importance(), index = features,\n                                        columns = [\"feature_importance\"]).reset_index()\n            importance_df.to_csv(CFG.MODEL_DATA_PATH/f'{method}_fold{fold + 1}_{CFG.PREFIX}_importance.csv', index=False)\n            \n        if method == \"xgboost\":\n            model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid)\n            \n        if method == \"catboost\":\n            model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid)\n            \n        \n        # saving bast model\n        pickle.dump(model, open(CFG.MODEL_DATA_PATH/f\"{method}_fold{fold + 1}_{CFG.PREFIX}.pkl\", \"wb\"))\n        \n        # Add to out of folds array\n        oof_predictions[train_df[\"cv_flag\"] == fold + 1] = valid_pred\n        del x_train, y_train, valid_df, x_valid, y_valid, valid_pred, model\n        gc.collect()\n        \n    train_df[\"pred\"] = oof_predictions\n    \n    # creating a dataframe to store out of folds predictions\n    np.save(CFG.OOF_DATA_PATH/f\"oof_{method}_{CFG.PREFIX}\", oof_predictions)\n            \n        \n\n            \n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T15:55:17.915400Z","iopub.execute_input":"2025-07-27T15:55:17.915651Z","iopub.status.idle":"2025-07-27T15:55:17.936987Z","shell.execute_reply.started":"2025-07-27T15:55:17.915629Z","shell.execute_reply":"2025-07-27T15:55:17.936095Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# loading data","metadata":{}},{"cell_type":"code","source":"train_df = pl.read_csv(CFG.DATA_PATH/\"train.csv\").to_pandas()\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T15:55:17.937903Z","iopub.execute_input":"2025-07-27T15:55:17.938176Z","iopub.status.idle":"2025-07-27T15:55:18.078882Z","shell.execute_reply.started":"2025-07-27T15:55:17.938154Z","shell.execute_reply":"2025-07-27T15:55:18.077781Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"      date_id  LME_AH_Close  LME_CA_Close  LME_PB_Close  LME_ZS_Close  \\\n0           0        2264.5        7205.0        2570.0        3349.0   \n1           1        2228.0        7147.0        2579.0        3327.0   \n2           2        2250.0        7188.5        2587.0        3362.0   \n3           3        2202.5        7121.0        2540.0        3354.0   \n4           4        2175.0        7125.0        2604.0        3386.0   \n...       ...           ...           ...           ...           ...   \n1912     1912        2450.0        9523.5        1961.5        2676.5   \n1913     1913        2471.5        9519.5        1980.5        2710.5   \n1914     1914        2471.5        9533.5        1974.0        2693.0   \n1915     1915        2456.0        9500.5        1970.0        2697.5   \n1916     1916        2463.5        9610.0        1991.0        2701.5   \n\n      JPX_Gold_Mini_Futures_Open  JPX_Gold_Rolling-Spot_Futures_Open  \\\n0                            NaN                                 NaN   \n1                            NaN                                 NaN   \n2                         4684.0                              4691.0   \n3                         4728.0                              4737.0   \n4                            NaN                                 NaN   \n...                          ...                                 ...   \n1912                     15086.0                             15440.0   \n1913                     15165.0                             15509.0   \n1914                     15040.0                             15477.0   \n1915                     15420.0                             15752.0   \n1916                     15416.0                             15802.0   \n\n      JPX_Gold_Standard_Futures_Open  JPX_Platinum_Mini_Futures_Open  \\\n0                                NaN                             NaN   \n1                                NaN                             NaN   \n2                             4684.0                          3363.0   \n3                             4729.0                          3430.0   \n4                                NaN                             NaN   \n...                              ...                             ...   \n1912                         15085.0                          4461.5   \n1913                         15162.0                          4495.0   \n1914                         15044.0                          4544.5   \n1915                         15420.0                          4670.0   \n1916                         15415.0                          4730.5   \n\n      JPX_Platinum_Standard_Futures_Open  ...  FX_GBPCAD  FX_CADCHF  \\\n0                                    NaN  ...   1.699987   0.776874   \n1                                    NaN  ...   1.695279   0.778682   \n2                                 3367.0  ...   1.692724   0.780186   \n3                                 3426.0  ...   1.683111   0.785329   \n4                                    NaN  ...   1.684816   0.787264   \n...                                  ...  ...        ...        ...   \n1912                              4467.0  ...   1.864661   0.598318   \n1913                              4490.0  ...   1.863539   0.594400   \n1914                              4555.0  ...   1.860067   0.595250   \n1915                              4685.0  ...   1.859624   0.597780   \n1916                              4751.0  ...   1.860472   0.597644   \n\n      FX_NZDCAD  FX_NZDCHF  FX_ZAREUR  FX_NOKGBP  FX_NOKCHF  FX_ZARCHF  \\\n0      0.888115   0.689954   0.066653   0.090582   0.119630   0.078135   \n1      0.889488   0.692628   0.067354   0.091297   0.120520   0.079066   \n2      0.894004   0.697490   0.067394   0.091478   0.120809   0.079287   \n3      0.889439   0.698502   0.067639   0.091558   0.121021   0.079285   \n4      0.891042   0.701485   0.067443   0.091266   0.121055   0.078925   \n...         ...        ...        ...        ...        ...        ...   \n1912   0.827529   0.495125   0.049224   0.072574   0.080968   0.046175   \n1913   0.824390   0.490018   0.049409   0.072828   0.080671   0.046113   \n1914   0.822392   0.489529   0.049095   0.073232   0.081083   0.045901   \n1915   0.817224   0.488520   0.049205   0.073018   0.081170   0.045987   \n1916   0.822219   0.491394   0.049321   0.073058   0.081233   0.046037   \n\n      FX_NOKJPY  FX_ZARGBP  \n0     13.822740   0.059163  \n1     13.888146   0.059895  \n2     13.983675   0.060037  \n3     14.035571   0.059983  \n4     14.013760   0.059503  \n...         ...        ...  \n1912  14.058107   0.041388  \n1913  14.082236   0.041630  \n1914  14.126606   0.041457  \n1915  14.095322   0.041368  \n1916  14.107311   0.041404  \n\n[1917 rows x 558 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_id</th>\n      <th>LME_AH_Close</th>\n      <th>LME_CA_Close</th>\n      <th>LME_PB_Close</th>\n      <th>LME_ZS_Close</th>\n      <th>JPX_Gold_Mini_Futures_Open</th>\n      <th>JPX_Gold_Rolling-Spot_Futures_Open</th>\n      <th>JPX_Gold_Standard_Futures_Open</th>\n      <th>JPX_Platinum_Mini_Futures_Open</th>\n      <th>JPX_Platinum_Standard_Futures_Open</th>\n      <th>...</th>\n      <th>FX_GBPCAD</th>\n      <th>FX_CADCHF</th>\n      <th>FX_NZDCAD</th>\n      <th>FX_NZDCHF</th>\n      <th>FX_ZAREUR</th>\n      <th>FX_NOKGBP</th>\n      <th>FX_NOKCHF</th>\n      <th>FX_ZARCHF</th>\n      <th>FX_NOKJPY</th>\n      <th>FX_ZARGBP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2264.5</td>\n      <td>7205.0</td>\n      <td>2570.0</td>\n      <td>3349.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.699987</td>\n      <td>0.776874</td>\n      <td>0.888115</td>\n      <td>0.689954</td>\n      <td>0.066653</td>\n      <td>0.090582</td>\n      <td>0.119630</td>\n      <td>0.078135</td>\n      <td>13.822740</td>\n      <td>0.059163</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2228.0</td>\n      <td>7147.0</td>\n      <td>2579.0</td>\n      <td>3327.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.695279</td>\n      <td>0.778682</td>\n      <td>0.889488</td>\n      <td>0.692628</td>\n      <td>0.067354</td>\n      <td>0.091297</td>\n      <td>0.120520</td>\n      <td>0.079066</td>\n      <td>13.888146</td>\n      <td>0.059895</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2250.0</td>\n      <td>7188.5</td>\n      <td>2587.0</td>\n      <td>3362.0</td>\n      <td>4684.0</td>\n      <td>4691.0</td>\n      <td>4684.0</td>\n      <td>3363.0</td>\n      <td>3367.0</td>\n      <td>...</td>\n      <td>1.692724</td>\n      <td>0.780186</td>\n      <td>0.894004</td>\n      <td>0.697490</td>\n      <td>0.067394</td>\n      <td>0.091478</td>\n      <td>0.120809</td>\n      <td>0.079287</td>\n      <td>13.983675</td>\n      <td>0.060037</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2202.5</td>\n      <td>7121.0</td>\n      <td>2540.0</td>\n      <td>3354.0</td>\n      <td>4728.0</td>\n      <td>4737.0</td>\n      <td>4729.0</td>\n      <td>3430.0</td>\n      <td>3426.0</td>\n      <td>...</td>\n      <td>1.683111</td>\n      <td>0.785329</td>\n      <td>0.889439</td>\n      <td>0.698502</td>\n      <td>0.067639</td>\n      <td>0.091558</td>\n      <td>0.121021</td>\n      <td>0.079285</td>\n      <td>14.035571</td>\n      <td>0.059983</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2175.0</td>\n      <td>7125.0</td>\n      <td>2604.0</td>\n      <td>3386.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.684816</td>\n      <td>0.787264</td>\n      <td>0.891042</td>\n      <td>0.701485</td>\n      <td>0.067443</td>\n      <td>0.091266</td>\n      <td>0.121055</td>\n      <td>0.078925</td>\n      <td>14.013760</td>\n      <td>0.059503</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1912</th>\n      <td>1912</td>\n      <td>2450.0</td>\n      <td>9523.5</td>\n      <td>1961.5</td>\n      <td>2676.5</td>\n      <td>15086.0</td>\n      <td>15440.0</td>\n      <td>15085.0</td>\n      <td>4461.5</td>\n      <td>4467.0</td>\n      <td>...</td>\n      <td>1.864661</td>\n      <td>0.598318</td>\n      <td>0.827529</td>\n      <td>0.495125</td>\n      <td>0.049224</td>\n      <td>0.072574</td>\n      <td>0.080968</td>\n      <td>0.046175</td>\n      <td>14.058107</td>\n      <td>0.041388</td>\n    </tr>\n    <tr>\n      <th>1913</th>\n      <td>1913</td>\n      <td>2471.5</td>\n      <td>9519.5</td>\n      <td>1980.5</td>\n      <td>2710.5</td>\n      <td>15165.0</td>\n      <td>15509.0</td>\n      <td>15162.0</td>\n      <td>4495.0</td>\n      <td>4490.0</td>\n      <td>...</td>\n      <td>1.863539</td>\n      <td>0.594400</td>\n      <td>0.824390</td>\n      <td>0.490018</td>\n      <td>0.049409</td>\n      <td>0.072828</td>\n      <td>0.080671</td>\n      <td>0.046113</td>\n      <td>14.082236</td>\n      <td>0.041630</td>\n    </tr>\n    <tr>\n      <th>1914</th>\n      <td>1914</td>\n      <td>2471.5</td>\n      <td>9533.5</td>\n      <td>1974.0</td>\n      <td>2693.0</td>\n      <td>15040.0</td>\n      <td>15477.0</td>\n      <td>15044.0</td>\n      <td>4544.5</td>\n      <td>4555.0</td>\n      <td>...</td>\n      <td>1.860067</td>\n      <td>0.595250</td>\n      <td>0.822392</td>\n      <td>0.489529</td>\n      <td>0.049095</td>\n      <td>0.073232</td>\n      <td>0.081083</td>\n      <td>0.045901</td>\n      <td>14.126606</td>\n      <td>0.041457</td>\n    </tr>\n    <tr>\n      <th>1915</th>\n      <td>1915</td>\n      <td>2456.0</td>\n      <td>9500.5</td>\n      <td>1970.0</td>\n      <td>2697.5</td>\n      <td>15420.0</td>\n      <td>15752.0</td>\n      <td>15420.0</td>\n      <td>4670.0</td>\n      <td>4685.0</td>\n      <td>...</td>\n      <td>1.859624</td>\n      <td>0.597780</td>\n      <td>0.817224</td>\n      <td>0.488520</td>\n      <td>0.049205</td>\n      <td>0.073018</td>\n      <td>0.081170</td>\n      <td>0.045987</td>\n      <td>14.095322</td>\n      <td>0.041368</td>\n    </tr>\n    <tr>\n      <th>1916</th>\n      <td>1916</td>\n      <td>2463.5</td>\n      <td>9610.0</td>\n      <td>1991.0</td>\n      <td>2701.5</td>\n      <td>15416.0</td>\n      <td>15802.0</td>\n      <td>15415.0</td>\n      <td>4730.5</td>\n      <td>4751.0</td>\n      <td>...</td>\n      <td>1.860472</td>\n      <td>0.597644</td>\n      <td>0.822219</td>\n      <td>0.491394</td>\n      <td>0.049321</td>\n      <td>0.073058</td>\n      <td>0.081233</td>\n      <td>0.046037</td>\n      <td>14.107311</td>\n      <td>0.041404</td>\n    </tr>\n  </tbody>\n</table>\n<p>1917 rows × 558 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_df = pl.read_csv(CFG.DATA_PATH/\"train.csv\").to_pandas()\ntrain_df[\"cv_flag\"] = pd.qcut(train_df.index, CFG.N_SPLIT, labels = False) + 1\n\ntrain_labels_df = pl.read_csv(CFG.DATA_PATH /\"train_labels.csv\").to_pandas()\n\noriginal_features = list(train_df.columns[1:]) # except \"date_id\"\n\ntarget_cols = list(train_labels_df.columns[1:]) # except \"date_id\"\n\n# combining train_df + targets\ntraining_df = []\nfor i, target_col in enumerate(target_cols):\n    temp_train_df = train_df.copy()\n    temp_train_df[\"target_id\"] = i\n    \n    # if i == 2:\n    #      break\n\n    y = train_labels_df[target_col].values # date_id順のターゲット値\n    temp_train_df[\"target\"] = y\n    #print(np.isinf(y).sum())\n    #print((np.abs(y) > 1e10).sum())\n    mask = ~(np.isnan(y) | np.isinf(y) | (np.abs(y) > 1e10))\n    training_df.append(temp_train_df[mask].copy())\ntraining_df = pd.concat(training_df).reset_index(drop = True) # 元のidxは保持しない","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T15:55:18.079880Z","iopub.execute_input":"2025-07-27T15:55:18.080148Z","iopub.status.idle":"2025-07-27T15:55:27.951158Z","shell.execute_reply.started":"2025-07-27T15:55:18.080116Z","shell.execute_reply":"2025-07-27T15:55:27.950434Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### MODEL TRAINING","metadata":{}},{"cell_type":"code","source":"for method in CFG.METHOD_LIST:\n    gradient_boosting_model_cv_training(method, training_df.copy(),\n                                        original_features + ['target_id'], target_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T15:55:27.952192Z","iopub.execute_input":"2025-07-27T15:55:27.952663Z","iopub.status.idle":"2025-07-27T16:06:03.297088Z","shell.execute_reply.started":"2025-07-27T15:55:27.952631Z","shell.execute_reply":"2025-07-27T16:06:03.295811Z"}},"outputs":[{"name":"stdout","text":"--------------------------------------------------\nlightgbm training fold 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.130148 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 141011\n[LightGBM] [Info] Number of data points in the train set: 580900, number of used features: 554\n[LightGBM] [Info] Start training from score -0.000043\nTraining until validation scores don't improve for 10 rounds\nEarly stopping, best iteration is:\n[1]\ttraining's rmse: 0.0331328\tvalid_1's rmse: 0.0255751\n--------------------------------------------------\nlightgbm training fold 2\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.160089 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 142221\n[LightGBM] [Info] Number of data points in the train set: 580627, number of used features: 559\n[LightGBM] [Info] Start training from score -0.000037\nTraining until validation scores don't improve for 10 rounds\n[50]\ttraining's rmse: 0.0286241\tvalid_1's rmse: 0.0419477\nEarly stopping, best iteration is:\n[78]\ttraining's rmse: 0.0286228\tvalid_1's rmse: 0.0419475\n--------------------------------------------------\nlightgbm training fold 3\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.175375 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 142222\n[LightGBM] [Info] Number of data points in the train set: 583186, number of used features: 559\n[LightGBM] [Info] Start training from score -0.000084\nTraining until validation scores don't improve for 10 rounds\nEarly stopping, best iteration is:\n[1]\ttraining's rmse: 0.0316638\tvalid_1's rmse: 0.0321459\n--------------------------------------------------\nlightgbm training fold 4\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.170214 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 142221\n[LightGBM] [Info] Number of data points in the train set: 580602, number of used features: 559\n[LightGBM] [Info] Start training from score -0.000011\nTraining until validation scores don't improve for 10 rounds\n[50]\ttraining's rmse: 0.0322821\tvalid_1's rmse: 0.0295403\nEarly stopping, best iteration is:\n[48]\ttraining's rmse: 0.0322826\tvalid_1's rmse: 0.0295403\n--------------------------------------------------\nlightgbm training fold 5\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.211340 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 142205\n[LightGBM] [Info] Number of data points in the train set: 582321, number of used features: 559\n[LightGBM] [Info] Start training from score -0.000046\nTraining until validation scores don't improve for 10 rounds\nEarly stopping, best iteration is:\n[5]\ttraining's rmse: 0.0328677\tvalid_1's rmse: 0.0268364\n--------------------------------------------------\nxgboost training fold 1\n[0]\ttrain-rmse:0.03313\teval-rmse:0.02558\n[9]\ttrain-rmse:0.03313\teval-rmse:0.02558\n--------------------------------------------------\nxgboost training fold 2\n[0]\ttrain-rmse:0.02863\teval-rmse:0.04195\n[50]\ttrain-rmse:0.02862\teval-rmse:0.04195\n[90]\ttrain-rmse:0.02862\teval-rmse:0.04195\n--------------------------------------------------\nxgboost training fold 3\n[0]\ttrain-rmse:0.03166\teval-rmse:0.03215\n[9]\ttrain-rmse:0.03166\teval-rmse:0.03215\n--------------------------------------------------\nxgboost training fold 4\n[0]\ttrain-rmse:0.03229\teval-rmse:0.02954\n[50]\ttrain-rmse:0.03228\teval-rmse:0.02954\n[100]\ttrain-rmse:0.03227\teval-rmse:0.02954\n[121]\ttrain-rmse:0.03227\teval-rmse:0.02954\n--------------------------------------------------\nxgboost training fold 5\n[0]\ttrain-rmse:0.03287\teval-rmse:0.02684\n[19]\ttrain-rmse:0.03286\teval-rmse:0.02684\n--------------------------------------------------\ncatboost training fold 1\n0:\tlearn: 0.0331332\ttest: 0.0255751\tbest: 0.0255751 (0)\ttotal: 351ms\tremaining: 14m 36s\nStopped by overfitting detector  (10 iterations wait)\n\nbestTest = 0.02557510314\nbestIteration = 0\n\nShrink model to first 1 iterations.\n--------------------------------------------------\ncatboost training fold 2\n0:\tlearn: 0.0286268\ttest: 0.0419480\tbest: 0.0419480 (0)\ttotal: 403ms\tremaining: 16m 47s\nStopped by overfitting detector  (10 iterations wait)\n\nbestTest = 0.04194795677\nbestIteration = 1\n\nShrink model to first 2 iterations.\n--------------------------------------------------\ncatboost training fold 3\n0:\tlearn: 0.0316639\ttest: 0.0321459\tbest: 0.0321459 (0)\ttotal: 280ms\tremaining: 11m 39s\nStopped by overfitting detector  (10 iterations wait)\n\nbestTest = 0.03214593681\nbestIteration = 0\n\nShrink model to first 1 iterations.\n--------------------------------------------------\ncatboost training fold 4\n0:\tlearn: 0.0322950\ttest: 0.0295403\tbest: 0.0295403 (0)\ttotal: 287ms\tremaining: 11m 57s\nStopped by overfitting detector  (10 iterations wait)\n\nbestTest = 0.02954027291\nbestIteration = 3\n\nShrink model to first 4 iterations.\n--------------------------------------------------\ncatboost training fold 5\n0:\tlearn: 0.0328681\ttest: 0.0268364\tbest: 0.0268364 (0)\ttotal: 276ms\tremaining: 11m 29s\nStopped by overfitting detector  (10 iterations wait)\n\nbestTest = 0.02683639555\nbestIteration = 4\n\nShrink model to first 5 iterations.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### feature_importance","metadata":{}},{"cell_type":"code","source":"pd.read_csv(\"/kaggle/working/models/lightgbm_fold3_seed42_ver1_importance.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T16:06:03.299589Z","iopub.execute_input":"2025-07-27T16:06:03.299979Z","iopub.status.idle":"2025-07-27T16:06:03.315407Z","shell.execute_reply.started":"2025-07-27T16:06:03.299949Z","shell.execute_reply":"2025-07-27T16:06:03.314468Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                          index  feature_importance\n0                  LME_AH_Close                   0\n1                  LME_CA_Close                   0\n2                  LME_PB_Close                   0\n3                  LME_ZS_Close                   0\n4    JPX_Gold_Mini_Futures_Open                   0\n..                          ...                 ...\n554                   FX_ZARCHF                   0\n555                   FX_NOKJPY                   0\n556                   FX_ZARGBP                   0\n557                     cv_flag                   0\n558                   target_id                   2\n\n[559 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>feature_importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LME_AH_Close</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LME_CA_Close</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LME_PB_Close</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LME_ZS_Close</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>JPX_Gold_Mini_Futures_Open</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>554</th>\n      <td>FX_ZARCHF</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>555</th>\n      <td>FX_NOKJPY</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>556</th>\n      <td>FX_ZARGBP</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>557</th>\n      <td>cv_flag</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>558</th>\n      <td>target_id</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>559 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## output / variable image","metadata":{}},{"cell_type":"code","source":"y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T16:06:03.316845Z","iopub.execute_input":"2025-07-27T16:06:03.317106Z","iopub.status.idle":"2025-07-27T16:06:03.325417Z","shell.execute_reply.started":"2025-07-27T16:06:03.317084Z","shell.execute_reply":"2025-07-27T16:06:03.324641Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"array([ 0.02730989,  0.02094043,  0.00170587, ..., -0.12768791,\n       -0.01218726,         nan])"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# /tmp/ipykernel_36/1471824027.py:23: RuntimeWarning: invalid value encountered in greater\n#  mask = ~(np.isnan(y) | np.isinf(y) | (np.abs(y) > 1e10))\n\nnp.isnan(y).sum() # 189\nnp.isinf(y).sum() # 0\n(np.abs(y) > 1e10).sum() # 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T16:06:03.326236Z","iopub.execute_input":"2025-07-27T16:06:03.326458Z","iopub.status.idle":"2025-07-27T16:06:03.344439Z","shell.execute_reply.started":"2025-07-27T16:06:03.326438Z","shell.execute_reply":"2025-07-27T16:06:03.343470Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"mask = ~(np.isnan(y) | np.isinf(y) | (np.abs(y) > 1e10))\nmask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T16:06:03.345338Z","iopub.execute_input":"2025-07-27T16:06:03.345602Z","iopub.status.idle":"2025-07-27T16:06:03.366450Z","shell.execute_reply.started":"2025-07-27T16:06:03.345578Z","shell.execute_reply":"2025-07-27T16:06:03.365353Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([ True,  True,  True, ...,  True,  True, False])"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}